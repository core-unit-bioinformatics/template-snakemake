# Parameter and function docs for context: TEMPLATE

## Module: Snakefile

**Module file**: `workflow/Snakefile`

### Documentation level: TARGETRULE

1. run_all
    - datatype: <class 'snakemake.rules.Rule'>
    - documentation: 
```
    This is the default target rule to trigger
    the execution of all rules in the workflow.
    The 'run_all' rule includes the following three
    templated workflow tasks:
    1. dump the workflow config object into the results/ folder
    2. copy the sample sheet into the results/ folder (if applicable)
    3. create the workflow manifest file in the results/ folder (if applicable)

    The object 'WORKFLOW_OUTPUT' is a simple list containing all
    workflow outputs (files). This list is created in the module
    rules::commons::99_aggregate.smk
```

## Module: commons::05_docgen.smk

**Module file**: `workflow/rules/commons/05_docgen.smk`

### Documentation level: GLOBALOBJ

1. DOC_RECORDER
    - datatype: <class 'snakemake.workflow.DocRecorder'>
    - documentation: Instance of the `DocRecorder` class that is globally available to record documentation *in place*. The DocRecorder class has three member functions to record documentation about 'objects' (in the Python sense) in module contexts. At the beginning of each module, call the function `DOC_RECORDER.add_module_doc(...)` to start a new module context. After that, call the function `DOC_RECORDER.add_member_doc(...)` for each member (everything except functions/methods) of the module that you want to document. For functions and object methods, call `DOC_RECORDER.add_function_doc(...)`. The documentation is dumped as a Markdown file and thus supports (basic) Markdown syntax for emphasis etc. In order to generate the documentation, execute the workflow with the target rule `run_build_docs`.
2. DOCREC
    - datatype: <class 'snakemake.workflow.DocRecorder'>
    - documentation: Alias/short hand for DOC_RECORDER.
3. DocLevel
    - datatype: <class 'enum.EnumType'>
    - documentation: Enum listing the different documentation levels such as USERCONFIG and GLOBALVAR that need to be specified when documenting module 'members' and 'functions'. See documentation of the DOC_RECORDER object for more details. The currently supported levels are: (1) USERCONFIG; (2) TARGETRULE; (3) GLOBALVAR; (4) GLOBALFUN; (5) GLOBALOBJ; (6) OBJMETHOD; (7) DEVONLY

### Documentation level: OBJMETHOD

1. add_function_doc
    - datatype: <class 'snakemake.workflow.DocRecorder'>.<class 'method'>
    - documentation: 
```
    This function of the DocRecorder class / DOCREC instance
    must be called to document either module-level / global
    functions or class methods. In case of class methods,
    the documentation level is set to DocLevel.OBJMETHOD and to
    DocLevel.GLOBALFUN otherwise.

    Args:
        function (callable): function/method to document
        parent (None or class): parent class if class method

    Returns:
        None
```
2. add_member_doc
    - datatype: <class 'snakemake.workflow.DocRecorder'>.<class 'method'>
    - documentation: 
```
    This function of the DocRecorder class / DOCREC instance
    must be called to document module-level members, i.e. global
    variables, functions, objects, user configurables and
    developer-only information.

    Args:
        doc_level (DocLevel): the documentation level
        name (str): name of the documented thing
        thing (any): the documented thing (i.e., some Python object)
        documentation (str): the documentation for thing

    Returns:
        None

    Raises:
        ValueError: if doc_level in [
            DocLevel.OBJMETHOD
            DocLevel.GLOBALFUN
            DocLevel.TARGETRULE
        ]
```

### Documentation level: GLOBALOBJ

1. DocContext
    - datatype: <class 'enum.EnumType'>
    - documentation: Enum listing the different documentation contexts. The context is used to sort the dumped documentation Markdown file into `docs/<context>/autodoc.md`. The currently supported contexts are: (1) TEMPLATE; (2) WORKFLOW

### Documentation level: OBJMETHOD

1. add_rule_doc
    - datatype: <class 'snakemake.workflow.DocRecorder'>.<class 'method'>
    - documentation: 
```
    This function of the DocRecorder class / DOCREC instance
    must be called to document Snakemake rules that represent
    reasonable execution targets from the user perspective.
    Canonically, this applies to all rules in the main
    Snakefile and potentially also to aggregation-style
    rules at the end of individual workflow modules.

    Args:
        rule (snakemake.rules.Rule): rule to document

    Returns:
        None
```

## Module: commons::10-constants::00_legacy.smk

**Module file**: `workflow/rules/commons/10-constants/00_legacy.smk`

### Documentation level: DEVONLY

1. SNAKEMAKE_LEGACY_RUN
    - datatype: <class 'bool'>
    - documentation: This variable can be checked if it is critical to determine whether or not the workflow is executed with a Snakemake legacy version (typically v7) or with a more recent release (typically v9+).

## Module: commons::30-settings::00-infrastructure::00_hardware.smk

**Module file**: `workflow/rules/commons/30-settings/00-infrastructure/00_hardware.smk`

### Documentation level: USERCONFIG

1. CPU_HIGH
    - datatype: <class 'int'>
    - documentation: The number of CPU cores/threads to use for rules benefitting from high parallelization. Typical values are in the range of 16 to 24. See the help for CPU_LOW for more details.
2. CPU_LOW
    - datatype: <class 'int'>
    - documentation: The number of CPU cores/threads to use for rules benefitting from limited parallelization. Typical values are in the range of 2 to 6. Workflow developers refer to this value in the 'threads' directive of the relevant rules. Users can dynamically change this value via the command line, i.e. by setting --config cpu_low=N or by adding the entry cpu_low: N to any of the Snakemake YAML configuration files read via --configfiles.
3. CPU_MAX
    - datatype: <class 'int'>
    - documentation: The number of CPU cores/threads to use for rules benefitting from maximal parallelization. Typical values are in the range of 48 to 128. Note that this value must not be higher than the CPU limit of the infrastructure the workflow is running on. See the help for CPU_LOW for more details.
4. CPU_MEDIUM|CPU_MED
    - datatype: <class 'int'>
    - documentation: The number of CPU cores/threads to use for rules benefitting from modest parallelization. Typical values are in the range of 8 to 12. See the help for CPU_LOW for more details.

## Module: commons::30-settings::00-infrastructure::10_software.smk

**Module file**: `workflow/rules/commons/30-settings/00-infrastructure/10_software.smk`

### Documentation level: DEVONLY

1. ENV_MODULE_APPTAINER
    - datatype: <class 'str'>
    - documentation: The name of the env(ironment) module that loads the Apptainer executable into `$PATH`. This is typically only relevant in HPC environments. Apptainer is the successor of Singularity and needed to execute containerized tools. The template uses this variable if CUBI-style reference containers are used.

## Module: commons::05_docgen.smk

**Module file**: `workflow/rules/commons/05_docgen.smk`

### Documentation level: OBJMETHOD

1. add_module_doc
    - datatype: <class 'snakemake.workflow.DocRecorder'>.<class 'method'>
    - documentation: 
```
    This member function must be called at the beginning
    of each new module to record the documentation
    in the correct module file context.

    Args:
        doc_context (DocContext): documentation context enum type
        module_name (str or list of str): name of the module given as relative path

    Returns:
        None
```

## Module: commons::30-settings::10-runtime::00_snakemake.smk

**Module file**: `workflow/rules/commons/30-settings/10-runtime/00_snakemake.smk`

### Documentation level: GLOBALVAR

1. DEBUG
    - datatype: <class 'bool'>
    - documentation: Represents the info if the workflow is executed via `snakemake --debug [...]`, which allows to set breakpoints in `run:` blocks.
2. DRYRUN
    - datatype: <class 'bool'>
    - documentation: Represents the info if the workflow is executed via `snakemake --dryrun [...]`.
3. VERBOSE
    - datatype: <class 'bool'>
    - documentation: Represents the info if the workflow is executed via `snakemake --verbose [...]`, i.e. Snakemake is printing verbose/debugging output.

### Documentation level: DEVONLY

1. RUN_IN_DEV_MODE
    - datatype: <class 'bool'>
    - documentation: Represents the info if the workflow is executed via `snakemake --config devmode=True [...]`
2. RUN_IN_TEST_MODE
    - datatype: <class 'bool'>
    - documentation: Represents the info if the workflow is executed via `snakemake [...] run_tests` or `snakemake [...] run_tests_no_manifest`.
3. USE_APPTAINER
    - datatype: <class 'bool'>
    - documentation: Represents the info if the workflow uses Apptainer (Singularity) for software deployment.
4. USE_CONDA
    - datatype: <class 'bool'>
    - documentation: Represents the info if the workflow uses Conda for software deployment.
5. USE_ENV_MODULES
    - datatype: <class 'bool'>
    - documentation: Represents the info if the workflow uses '(environment) modules' for software deployment. This typically only applies to HPC infrastructures.
6. USE_SINGULARITY
    - datatype: <class 'bool'>
    - documentation: Represents the info if the workflow uses Singularity (Apptainer) for software deployment.

## Module: commons::30-settings::20-environment::05_paths.smk

**Module file**: `workflow/rules/commons/30-settings/20-environment/05_paths.smk`

### Documentation level: GLOBALVAR

1. DIR_BENCHMARK
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Relative path pointing to `rsrc` in the `WORKDIR`. Alias for DIR_RSRC.
2. DIR_CLUSTERLOG_ERR
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Relative path pointing to `log/cluster_jobs/err` in the `WORKDIR`. Only relevant in HPC environments. Intended to capture all stderr streams of executed rules/jobs (if applicable).
3. DIR_CLUSTERLOG_OUT
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Relative path pointing to `log/cluster_jobs/out` in the `WORKDIR`. Only relevant in HPC environments. Intended to capture all stdout streams of executed rules/jobs (if applicable).
4. DIR_ENVS
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Fully resolved directory path to `[..]/workflow/envs`. Any Conda environment yaml file used by the workflow can thus be addressed via `DIR_ENVS.joinpath(...)`.
5. DIR_GLOBAL_REF
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Relative path pointing to `global_ref` in the `WORKDIR`. This default directory is the source location for all reference data files that are *not* being produced by the workflow itself.

## Module: commons::30-settings::00-infrastructure::10_software.smk

**Module file**: `workflow/rules/commons/30-settings/00-infrastructure/10_software.smk`

### Documentation level: DEVONLY

1. ENV_MODULE_SINGULARITY
    - datatype: <class 'str'>
    - documentation: The name of the env(ironment) module that loads the Singularity executable into `$PATH`. This is typically only relevant in HPC environments. Note that Singularity is deprecated and has been replaced by Apptainer. The template uses this variable if CUBI-style reference containers are used.

## Module: commons::30-settings::20-environment::05_paths.smk

**Module file**: `workflow/rules/commons/30-settings/20-environment/05_paths.smk`

### Documentation level: GLOBALVAR

1. DIR_LOG
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Relative path pointing to `log` in the `WORKDIR`. All log files of the workflow can be addressed via `DIR_LOG.joinpath(...)` in Snakemake rules.
2. DIR_PROC
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Relative path pointing to `proc` in the `WORKDIR`. All non-result files of the workflow can be addressed via `DIR_PROC.joinpath(...)` in Snakemake rules.
3. DIR_REPO
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Recommended alias/shorthand for `DIR_REPOSITORY`, i.e. the fully resolved directory path to the workflow repository. By convention, this is always taken to be the parent of the `workflow/` directory.
4. DIR_RES
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Relative path pointing to `results` in the `WORKDIR`. All result files of the workflow can be addressed via `DIR_RES.joinpath(...)` in Snakemake rules.
5. DIR_RSRC
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Relative path pointing to `rsrc` in the `WORKDIR`. All resource ('benchmark') files of the workflow can be addressed via `DIR_LOG.joinpath(...)` in Snakemake rules.
6. DIR_SCRIPTS
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Fully resolved directory path to `[..]/workflow/scripts`. Any script used by the workflow can thus be addressed via `DIR_SCRIPTS.joinpath(...)`. See also the `get_script` function.
7. DIR_SNAKEFILE
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Fully resolved directory path in which the workflow's main snakefile resides. By convention, this path always ends with the last component `workflow/`.
8. DIR_WORKING
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Recommended global variable representing the fully resolved path to the Snakemake working directory, i.e. the content of the `--directory` / `-d` command line parameter. **CAUTION**: this parameter should only be used if absolutely necessary. All relevant directory paths should be addressed via the other global variables of this module.
9. NAME_SNAKEFILE
    - datatype: <class 'str'>
    - documentation: Name of the workflow's main snakefile, which is always `Snakefile` by convention / best practices.
10. PATH_SNAKEFILE
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Fully resolved file path of the workflow's main snakefile.
11. WORKDIR
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Alias/shorthand for `DIR_WORKING`.

### Documentation level: DEVONLY

1. WD_PATHS_MUST_RESOLVE
    - datatype: <class 'bool'>
    - documentation: If the workflow is executed with `--config devmode=True`, non-existing default paths are ignored and do not raise an error.

## Module: commons::40-pyutils::05_simple_get.smk

**Module file**: `workflow/rules/commons/40-pyutils/05_simple_get.smk`

### Documentation level: GLOBALFUN

1. find_script
    - datatype: <class 'function'>
    - documentation: 
```
    Original version of 'get_script'.

    DEPRECATED FUNCTION --- see 'get_script'
```
2. get_hostname
    - datatype: <class 'function'>
    - documentation: 
```
    Returns:
    host (str): name of host machine
```
3. get_script
    - datatype: <class 'function'>
    - documentation: 
```
    Utility function to locate script files underneath
    DIR_SCRIPTS. The intended usage context is inside
    a 'params' block, i.e.:

    rule rule_with_script:
        [...]
    params:
        script = get_script("script_name")
    shell:
        '{params.script} [...do scripted task...]'

    Args:
    script_name (str): file name of the script to be located
    extension (str): file extension of the script to be locate; default 'py'

    Returns:
    selected_script (str): full path to script file

    Raises:
    ValueError: no script or more than one match found
```
4. get_timestamp
    - datatype: <class 'function'>
    - documentation: 
```
    Get naive (not timezone-aware)
    timestamp representing 'now'.
    The formatting is following
    ISO 8601 w/o timezone offset, i.e.
    YYYY-MM-DDThh-mm-ss
    (24-hour format for time)

    Returns:
    ts (str): timestamp of 'now' w/o tz
```
5. get_username
    - datatype: <class 'function'>
    - documentation: 
```
    Returns:
    user (str): login name of current user
```

## Module: commons::40-pyutils::15_simple_logging.smk

**Module file**: `workflow/rules/commons/40-pyutils/15_simple_logging.smk`

### Documentation level: GLOBALFUN

1. log_err
    - datatype: <class 'function'>
    - documentation: 
```
    Alias for 'loggerr'
```
2. log_out
    - datatype: <class 'function'>
    - documentation: 
```
    Alias for 'logout'
```
3. logerr
    - datatype: <class 'function'>
    - documentation: 
```
    Log a message to sys.stderr.
    If VERBOSE is set, the level is
    set to 'VERBOSE (err/dbg)' and to
    'ERROR' otherwise. The message is
    prefixed with the current timestamp.

    Args:
    msg (str): message text

    Returns:
    None
```
4. logout
    - datatype: <class 'function'>
    - documentation: 
```
    Log a message to sys.stdout with level
    INFO. The message is prefixed with
    the current timestamp.

    Args:
    msg (str): message text

    Returns:
    None
```
5. write_log_message
    - datatype: <class 'function'>
    - documentation: 
```
    Log a message with info 'level' to 'stream',
    which must feature a write method. By default,
    the 'message' is prefixed with the current timestamp.

    TODO - introduce enum type for levels?
    Level should be informative such as ERROR,
    WARNING, DEBUG and so on but is not sanity-checked.

    Args:
    stream (object): must support write method
    level (str): informative severity level
    message (str): the message to be logged

    Returns:
    None
```

## Module: commons::40-pyutils::85_template_accounting.smk

**Module file**: `workflow/rules/commons/40-pyutils/85_template_accounting.smk`

### Documentation level: GLOBALFUN

1. _load_data_line
    - datatype: <class 'function'>
    - documentation: 
```
    Simple utility function that reads the file metadata
    (= file size or checksums) from the respective files
    on disk.

    Args:
    file_path: path to metadata file, i.e. *.md5 / *.bytes / *.sha256
    Returns:
    str: the respective metadata value, i.e. a checksum or file size
```
2. load_accounting_information
    - datatype: <class 'function'>
    - documentation: 
```
    This function loads the file paths from all
    three accounting files to force creation
    (relevant for checksum and size files).

    Args:
    wildcards: required argument because the function
    is called as an input function of a Snakemake rule;
    wildcards are not processed in this function
    (constant output)
    Returns:
    List[str] : the file paths of the three
    accounting files (input, reference and results)
```
3. load_file_by_path_id
    - datatype: <class 'function'>
    - documentation: 
```
    Simple utility function that extracts
    the source file path from the accounting
    files.

    Args:
    wildcards: contains the wildcards to select
        the correct account type (input, reference, result)
        and the path ID that uniquely identifies
        the file.
    Returns:
    str: source file path
```
4. process_accounting_record
    - datatype: <class 'function'>
    - documentation: 
```
    This function is called for each entry in the accounting
    files (= one input, reference or result file) and then
    determines what information has to be gathered:
    checksum / size / file metadata such as name.

    Args:
    line: a string line from an accounting file
    Returns:
    str, dict: the path ID (= unique file key) and
        the collected metadata such as the file
        checksum or size
```
5. register_input
    - datatype: <class 'function'>
    - documentation: 
```
    TODO: potential breaking change - ?
    Fix English for keyword argument: 'allow_non_existent'

    The 'register_input(...)' function must be used
    to register all files in the file accounting process
    that should appear as workflow input files in the
    final (file) manifest. Its use should have the following
    form:

    rule some_rule_name:
    input:
        ...
    params:
        acc_in=lambda wildcards, input: register_input(input)

    The above would register all files of the 'input' object
    as workflow input files and compute checksums and file sizes
    for all of them to be included in the workflow file manifest.

    Notably, this function assumes that all files exist when the
    workflow starts / the function is called, which is a logical
    necessity. There are edge cases such as the run config dump
    file, which is created as part of the workflow run and yet
    considered an input file (= no workflow run w/o config file).

    This register function has slightly
    different semantics because input files
    should always exist when the workflow starts.
    For special cases, a keyword-only argument can
    be set to accept non-existent files when the
    pipeline run starts and yet the files should
    be counted as input files. One of those
    special cases is the config dump, which is
    counted as part of the input (cannot run
    the workflow w/o config), but the dump
    is only created after execution.

    Args:
    args (any): a file path or a potentially nested object
        containing many file paths to be registered as
        workflow input files.
    allow_non_existing (bool): do not raise for non-existent files

    Returns:
    None: must be constant to avoid rerun triggers
        because of changing rule parameters.
```
6. register_reference
    - datatype: <class 'function'>
    - documentation: 
```
    Register reference file(s) for the workflow manifest.
    The difference between 'input' and 'reference' is mostly
    semantics, i.e., scientists typically distinguish between
    these two categories and so do we.

    Args:
    args (any): a file path or a potentially nested object
        containing many file paths to be registered as
        workflow input files.
    Returns:
    None: must be constant to avoid rerun triggers
        because of changing rule parameters.
```
7. register_result
    - datatype: <class 'function'>
    - documentation: 
```
    Register reference file(s) for the workflow manifest.
    The difference between 'input' and 'reference' is mostly
    semantics, i.e., scientists typically distinguish between
    these two categories and so do we.

    Args:
    args (any): a file path or a potentially nested object
        containing many file paths to be registered as
        workflow input files.
    Returns:
    None: must be constant to avoid rerun triggers
        because of changing rule parameters.
```

## Module: commons::40-pyutils::90_template_staging.smk

**Module file**: `workflow/rules/commons/40-pyutils/90_template_staging.smk`

### Documentation level: GLOBALFUN

1. _reset_file_accounts
    - datatype: <class 'function'>
    - documentation: 
```
    Why is this function needed?
    - The way the file accounting currently caches
    the entries about file metadata to produce (checksums
    and file size) can lead to errors during development
    of a workflow when fileA is replaced by fileB, but
    the accounting cache still contains fileA.md5,
    fileA.sha256 and fileA.size, which can no longer
    be generated because fileA is no longer produced
    by the workflow.

    In this case, the user needs to manually reset the
    file accounting cache via

    snakemake [...] --config resetacc=True [...]

    Notably, this only resets the cache, it does not
    delete already computed metadata files. After that,
    the user can simply update the cache as usual by
    running the workflow in dry run mode twice.

    TODO:
    - implement a clean up step that deletes metadata files
    that are no longer needed (little volume, but can be many
    files)
    - make caching dynamic to allow auto-delete of metadata
    entries that refer to non-existent files (dangerous because
    it may obscrue errors).

    Args:
    <none>
    Returns:
    <none>
```

## Module: commons::30-settings::20-environment::05_paths.smk

**Module file**: `workflow/rules/commons/30-settings/20-environment/05_paths.smk`

### Documentation level: GLOBALVAR

1. DIR_LOCAL_REF
    - datatype: <class 'pathlib.PosixPath'>
    - documentation: Relative path pointing to `local_ref` in the `WORKDIR`. This default directory is the target and source location for all reference data files that are produced programmatically by the workflow itself. In other words, for each file in `local_ref`, there must be a rule in the workflow that produces that file.

